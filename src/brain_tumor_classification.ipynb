{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9fe000-157f-4db7-8fa0-a25a9d499d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# test for GPU use in tensorflow\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "print(physical_gpus)\n",
    "\n",
    "# define variables and constants\n",
    "DIMX = 256\n",
    "IMAGE_SIZE = (DIMX, DIMX)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "BASE_DIR = './'\n",
    "IMAGE_DIR = BASE_DIR + 'images/'\n",
    "MODEL_DIR = BASE_DIR + 'models/'\n",
    "RESULTS_DIR = BASE_DIR + 'results/'\n",
    "DATASET_DIR = '../'\n",
    "USE_CPU = False\n",
    "\n",
    "if USE_CPU:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "print(\"Tensorflow version\", tf.__version__)\n",
    "print(\"Keras version\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b216300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy graphics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def draw_loss_acc_graphics(outfile, model_name, history):\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc)+1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'c', label='Validation acc')\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(outfile + '_accuracy_graph.pdf')  \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'c', label='Validation loss')\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(outfile + '_loss_graph.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8391003-8fc7-4648-99aa-f51d39a45860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate model with test set\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "def process_tests(model, test_ds):\n",
    "    y_true = np.array([], dtype=np.int32)\n",
    "    y_pred = np.array([], dtype=np.int32)\n",
    "    images = []\n",
    "    \n",
    "    for image_batch, labels in test_ds:\n",
    "        y_true = np.concatenate([y_true, np.argmax(labels.numpy(), axis=-1)])\n",
    "        y_pred = np.concatenate(\n",
    "            [y_pred, np.argmax(model.predict(image_batch,verbose=0), axis=-1)]\n",
    "        )\n",
    "        for img in image_batch:\n",
    "            images.append(img)\n",
    "\n",
    "    size_test = sum([len(l) for _,l in test_ds])\n",
    "    images = np.reshape(images, (size_test,DIMX,DIMX,3))\n",
    "   \n",
    "    return y_true, y_pred, images\n",
    "    \n",
    "def draw_confusion_matrix(outfile, model, model_name, test_ds, class_names):\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    y_true, y_pred, images = process_tests(model, test_ds)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    cmap = plt.cm.Blues #'viridis'\n",
    "\n",
    "    # save confusion matrix with classification percentage\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true, y_pred, cmap=cmap, labels=range(len(class_names)), \n",
    "        display_labels=class_names, normalize=\"pred\" \n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    ax = plt.gca()\n",
    "    plt.setp(ax.yaxis.get_majorticklabels(), rotation=90, ha=\"center\", rotation_mode=\"anchor\") \n",
    "    plt.savefig(outfile + '_cm.pdf')\n",
    "\n",
    "    # save confusion matrix with number of samples\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true, y_pred, cmap=cmap, labels=range(len(class_names)), \n",
    "        display_labels=class_names\n",
    "    )\n",
    "    plt.savefig(outfile + '_cm2.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    # calculate accuracy, precision, recall and F1-score\n",
    "    accuracy = metric.accuracy_score(y_true, y_pred)\n",
    "    precision = metric.precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall = metric.recall_score(y_true, y_pred, average=\"macro\")\n",
    "    f1 = metric.f1_score(y_true, y_pred, average=\"macro\")\n",
    "    print('Accuracy | Precision | Recall | F1 score')\n",
    "    print(accuracy, precision, recall, f1)\n",
    "    print(metric.precision_recall_fscore_support(y_true, y_pred, average=\"macro\"))\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_true, y_pred, labels=range(len(class_names)), \n",
    "        target_names=class_names\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    return precision, recall, f1, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf4892-777c-4e47-8f90-022baddd1f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def save_misclassified_images(outfile, model, model_name, test_ds, class_names, n_images=3):\n",
    "    \n",
    "    # save incorrectly classified test images \n",
    "    y_true, y_pred, images = process_tests(model, test_ds)\n",
    "\n",
    "    a = np.array(y_true) == np.array(y_pred)\n",
    "    plt.figure()\n",
    "    ax=plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    j=0\n",
    "    for i in range(len(a)):\n",
    "        if not a[i] and j<n_images:\n",
    "            j=j+1\n",
    "            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "            plt.title(class_names[y_true[i]] + \" - \" + class_names[y_pred[i]])\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(outfile + '_misclassified_' + str(j) + '.pdf')\n",
    "    plt.close()\n",
    "\n",
    "def save_results(\n",
    "    filename, model, model_name, train_ds, val_ds, test_ds, \n",
    "    class_names, history\n",
    "):\n",
    "    # loss-accuracy graphics\n",
    "    draw_loss_acc_graphics(IMAGE_DIR+filename, model_name, history)\n",
    "\n",
    "    # confusion matrix\n",
    "    precision, recall, f1, report = draw_confusion_matrix(\n",
    "        IMAGE_DIR+filename, model, model_name, test_ds, class_names\n",
    "    )   \n",
    "\n",
    "    # misclassified images\n",
    "    save_misclassified_images(\n",
    "        IMAGE_DIR+'misclassified/'+filename, model, \n",
    "        model_name, test_ds, class_names\n",
    "    )\n",
    "\n",
    "    # save results to file\n",
    "    train_loss, train_acc = model.evaluate(train_ds)\n",
    "    val_loss, val_acc     = model.evaluate(val_ds)\n",
    "    test_loss, test_acc   = model.evaluate(test_ds)\n",
    "\n",
    "    with open(RESULTS_DIR+filename+'.txt', 'w') as f:\n",
    "        f.write(\"Training loss/accuracy: \" + str(train_loss) + ', '\\\n",
    "                + str(train_acc) + '\\n')\n",
    "        f.write(\"Validate loss/accuracy: \" + str(val_loss) + ', '\\\n",
    "                + str(val_acc) + '\\n')\n",
    "        f.write(\"Testing  loss/accuracy: \" + str(test_loss) + ', '\\\n",
    "                + str(test_acc) + '\\n')\n",
    "        f.write(\"Precision: \" + str(precision) + '\\n')\n",
    "        f.write(\"Recall: \" + str(recall) + '\\n')\n",
    "        f.write(\"F1: \" + str(f1) + '\\n')\n",
    "        f.write(report + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d920e07-07f1-473f-8ec5-ff6568dc5763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "      \n",
    "def run_experiments(\n",
    "    dataset_name, model_name, train_ds, val_ds, test_ds, \n",
    "    class_names, epochs=EPOCHS, data_augmentation=False, \n",
    "    transfer_learning=False\n",
    "):\n",
    "\n",
    "    model = create_model(\n",
    "        model_name, len(class_names), DIMX, BATCH_SIZE, \n",
    "        data_augmentation, transfer_learning\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # save model to disk\n",
    "    filename = model_name + '_' + dataset_name \n",
    "    if data_augmentation:\n",
    "        filename = filename + '_DA'\n",
    "    if transfer_learning:\n",
    "        filename = filename + '_TL'\n",
    "\n",
    "    # save results and graphics to disk \n",
    "    save_results(\n",
    "        filename,model,model_name,train_ds,val_ds,\n",
    "        test_ds, class_names, history\n",
    "    )\n",
    "    \n",
    "    if transfer_learning and not data_augmentation:\n",
    "        # do fine-tuning after transfer learning\n",
    "        print(\"Fine-tuning the model\")\n",
    "        # model.layers[1].trainable=True #full fine-tuning\n",
    "        for layer in model.layers[1].layers[-15:]:\n",
    "            if not isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = True\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        model.compile(\n",
    "            optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        fine_tuned_history = model.fit(\n",
    "            train_ds.concatenate(val_ds), epochs=15, batch_size=BATCH_SIZE,\n",
    "            validation_data=test_ds, \n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # save fine-tuned results \n",
    "        save_results(\n",
    "            filename + '_fine-tuned', model, model_name,\n",
    "            train_ds, val_ds, test_ds, class_names, fine_tuned_history,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "def experiments_with_dataset(dataset, model_list, train_ds, val_ds, test_ds, class_names):\n",
    "    \n",
    "    print(\"Number of classes\", len(class_names))\n",
    "\n",
    "    for model_name in model_list:\n",
    "        print('# ' + model_name + ' model')\n",
    "         \n",
    "        # training from scratch\n",
    "        print('  ## training from scratch')\n",
    "        run_experiments(\n",
    "            dataset, model_name, train_ds, val_ds, \n",
    "            test_ds, class_names, EPOCHS\n",
    "        )\n",
    "        \n",
    "        # using data augmentation\n",
    "        print('  ## training with data augmentation')\n",
    "        run_experiments(\n",
    "            dataset, model_name, train_ds, val_ds, \n",
    "            test_ds, class_names, min(100,round(1.5*EPOCHS)), True\n",
    "        )\n",
    "        \n",
    "        if model_name != 'custom':\n",
    "            \n",
    "            # using transfer learning\n",
    "            print('  ## training with transfer learning')\n",
    "            run_experiments(\n",
    "                dataset, model_name, train_ds, val_ds, \n",
    "                test_ds, class_names, EPOCHS, False, True\n",
    "            )\n",
    "            \n",
    "            # using transfer learning and data augmentation\n",
    "            print('  ## training with transfer learning and data augmentation')\n",
    "            run_experiments(\n",
    "                dataset, model_name, train_ds, val_ds, \n",
    "                test_ds, class_names, min(100,round(1.5*EPOCHS)), True, True\n",
    "            )\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3f75b-a9e9-44fa-a40b-8e0d99b7114a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from load_datasets import load\n",
    "from create_model import create_model\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "datasets = ['figshare', 'kaggle']\n",
    "\n",
    "model_list = ['custom', 'vgg16', 'vgg19', \n",
    "              'resnet50v2', 'resnet101v2','resnet152v2', \n",
    "              'xception', 'densenet', 'mobilenet', \n",
    "              'efficientnetb0v2','efficientnetb3v2',\n",
    "              'convnexttiny'\n",
    "             ]\n",
    "m1 = 0\n",
    "m2 = None\n",
    "\n",
    "# experiments with Figshare\n",
    "print('\\nProcessing Figshare Dataset:')\n",
    "print('--------------------------------')\n",
    "train_ds1, val_ds1, test_ds1, class_names1 = load(\n",
    "    datasets[0], DATASET_DIR, IMAGE_SIZE, BATCH_SIZE, True\n",
    ")\n",
    "\n",
    "experiments_with_dataset(\n",
    "    datasets[0], model_list[m1:m2], train_ds1, \n",
    "    val_ds1, test_ds1, class_names1\n",
    ")\n",
    "\n",
    "# experiments with Kaggle\n",
    "print('\\nProcessing Kaggle Dataset:')\n",
    "print('--------------------------------')\n",
    "train_ds2, val_ds2, test_ds2, class_names2 = load(\n",
    "    datasets[1], DATASET_DIR, IMAGE_SIZE, BATCH_SIZE, True\n",
    ")\n",
    "\n",
    "experiments_with_dataset(\n",
    "    datasets[1], model_list[m1:m2], train_ds2, \n",
    "    val_ds2, test_ds2, class_names2\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
